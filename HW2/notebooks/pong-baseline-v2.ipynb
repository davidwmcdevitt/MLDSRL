{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961520fe-ada7-4893-b817-28791258f759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 24 22:59:16 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:05:00.0 Off |                  N/A |\n",
      "|  0%   26C    P8     7W / 198W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 30%   46C    P2    33W / 180W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 27%   44C    P0    51W / 180W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8    12W / 198W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c5063-5fe6-4ee0-80b9-dedd273dedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb5bf7-8f46-41db-a812-cf2a7f26e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e8d2d-fe77-4ad6-8fa5-914fab6d1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 2D float array \"\"\"\n",
    "    image = image[35:195] # crop\n",
    "    image = image[::2,::2,0] # downsample by factor of 2\n",
    "    image[image == 144] = 0 # erase background (background type 1)\n",
    "    image[image == 109] = 0 # erase background (background type 2)\n",
    "    image[image != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return np.reshape(image.astype(float).ravel(), [80,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc06110-30c4-4a0a-89a9-254b63bbeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-v0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed5b46-fbda-4de0-8854-1627642a2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 10 * 10, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Apply He initialization\n",
    "        init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.conv3.weight, nonlinearity='relu')\n",
    "        \n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = x.view(-1, 128 * 10 * 10)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760385e9-4b0a-4f0a-a4dd-7d695fd4ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 10 * 10, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Apply He initialization\n",
    "        init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.conv3.weight, nonlinearity='relu')\n",
    "        \n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = x.view(-1, 128 * 10 * 10)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e038ffd-bca5-4191-8a03-e81fa77160ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(policy_net, state, prior, method):\n",
    "  if method == \"random\":\n",
    "    action = np.random.choice(2) + 2\n",
    "    probs = np.array([[0.5, 0.5]])\n",
    "  if method == \"gradient\":\n",
    "    screen = torch.tensor(preprocess(state)).unsqueeze(0).float()\n",
    "    screen = screen.to(device)\n",
    "    prior = prior.to(device)\n",
    "    screen = screen - prior\n",
    "    probs = policy_net(screen.unsqueeze(0))\n",
    "    prior = screen\n",
    "    \n",
    "    try:\n",
    "        probs = probs.cpu().detach().numpy()\n",
    "        action = np.random.choice(2, p=probs) + 2\n",
    "    except ValueError:\n",
    "        action = np.random.choice(2) + 2\n",
    "\n",
    "  return action, probs, prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c73c6f-75d2-4762-ac76-074eafef9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "policy_net = PolicyNetwork().to(device)\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=0.0001)\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906b425-18d4-4ac1-82a8-f9ce7c1c3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net = ValueNetwork().to(device)\n",
    "\n",
    "value_optimizer = optim.Adam(value_net.parameters(), lr=0.001)\n",
    "\n",
    "value_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feab26-4ab9-4e55-8ee4-63d1b9321a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_episode = 0\n",
    "longest_episode_length = 0\n",
    "longest_episode_path = \"\"\n",
    "episode_lengths = []\n",
    "loss_list = []\n",
    "rolling_rewards = []\n",
    "rolling_rewards_avg = []\n",
    "rolling_time_avg = []\n",
    "rolling_loss = []\n",
    "value_list = []\n",
    "val_avg = []\n",
    "rolling_val = []\n",
    "\n",
    "episode =  0\n",
    "count = 0\n",
    "cooldown = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4b86a-bc9e-4a28-9a20-f05bf58c23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(10000):\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    t = 0\n",
    "    \n",
    "    obs_history = []\n",
    "    action_history = []\n",
    "    episode_rewards = []\n",
    "    saved_log_probs = []\n",
    "    state_hist = []\n",
    "    action_hist = []\n",
    "    \n",
    "    terminated, truncated = False, False\n",
    "    \n",
    "    prior = torch.zeros((1, 80, 80))\n",
    "    \n",
    "    while not terminated:\n",
    "        state_hist.append(torch.FloatTensor(preprocess(state)))\n",
    "        t+=1'''\n",
    "        if (episode) % 25 == 0:\n",
    "            action, probs, prior = get_action(policy_net, state, prior, \"random\")\n",
    "        else:\n",
    "        '''\n",
    "        action, probs, prior = get_action(policy_net, state, prior, \"gradient\")\n",
    "            \n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        obs_history.append(observation)\n",
    "        episode_rewards.append(reward)\n",
    "        action_history.append(action)\n",
    "        saved_log_probs.append(torch.tensor(np.log(probs)[0][action-2]))\n",
    "        print(probs)\n",
    "        print(probs[0])\n",
    "        print(np.log(probs)[0][action-2])\n",
    "        action_hist.append(action)\n",
    "        \n",
    "        \n",
    "    rolling_rewards.append(sum(episode_rewards))\n",
    "    rolling_rewards_avg.append(np.mean(rolling_rewards[-100:]))\n",
    "    discounted_rewards = []\n",
    "    R = 0\n",
    "    for i, r in enumerate(reversed(episode_rewards)):\n",
    "        #r = 10 * r + 1\n",
    "        #if episode_rewards[i] != 0: R = 0\n",
    "        R = r + gamma * R\n",
    "        discounted_rewards.insert(0, R)\n",
    "\n",
    "    discounted_rewards = torch.tensor(discounted_rewards)\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    criterion = nn.MSELoss()\n",
    "    advantages = []\n",
    "    '''\n",
    "    for i, j in zip(state_hist,discounted_rewards):\n",
    "        state_input = i.unsqueeze(0).unsqueeze(0)\n",
    "        state_input = state_input.to(device)\n",
    "        reward_input = j.to(device)\n",
    "        value_pred = value_net(state_input)\n",
    "        value_loss = criterion(value_pred, reward_input)\n",
    "        value_loss.backward()\n",
    "        value_optimizer.step()\n",
    "        advantages.append(reward_input - value_pred)\n",
    "    '''\n",
    "    batch_size = 32\n",
    "    \n",
    "    state_hist_tensor = torch.stack(state_hist) \n",
    "    discounted_rewards_tensor = torch.Tensor(discounted_rewards)\n",
    "    \n",
    "    dataset = TensorDataset(state_hist_tensor, discounted_rewards_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    value_losses = []\n",
    "\n",
    "    for batch_idx, (batch_states, batch_rewards) in enumerate(dataloader):\n",
    "        batch_states = batch_states.to(device)\n",
    "        batch_states = batch_states.unsqueeze(1)\n",
    "        batch_rewards = batch_rewards.to(device)\n",
    "\n",
    "        value_pred = value_net(batch_states).squeeze(1)\n",
    "        value_loss = criterion(value_pred, batch_rewards)\n",
    "        \n",
    "        value_losses.append(value_loss)\n",
    "\n",
    "        value_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        value_optimizer.step()\n",
    "        \n",
    "        adv = batch_rewards - value_pred.detach()\n",
    "        adv = adv.to('cpu')\n",
    "\n",
    "        advantages.append(adv)\n",
    "    \n",
    "    \n",
    "    val_avg.append(sum(value_losses)/len(value_losses))\n",
    "        \n",
    "    policy_loss = -torch.mean(torch.tensor(saved_log_probs, requires_grad=True) * torch.cat(advantages))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    nn.utils.clip_grad_norm_(policy_net.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    episode_lengths.append(t)\n",
    "    \n",
    "    loss_list.append(policy_loss.cpu().detach().numpy())\n",
    "    rolling_loss.append(np.mean(loss_list[-100:]))\n",
    "    rolling_time_avg.append(np.mean(episode_lengths[-100:]))\n",
    "    \n",
    "    \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(\"-\"*50)\n",
    "        print(f\"Episode {episode+1} finished after {t} time steps.\")\n",
    "        print(f\"Episode {episode+1} average time per 100: {np.mean(episode_lengths[-100:])} time steps.\")\n",
    "        print(f\"Episode {episode + 1} rolling loss: {np.mean(loss_list[-100:])}\")\n",
    "        print(f\"Episode {episode + 1} discounted rewards: {torch.mean(discounted_rewards)}\")\n",
    "        print(f\"Episode {episode + 1} saved log probs: {np.mean(saved_log_probs)}\")\n",
    "        print(f\"Episode {episode + 1} Action Means: {np.mean(action_history)}\")\n",
    "        print(f\"Episode {episode + 1} Reward Rolling Average per 100: {np.mean(rolling_rewards[-100:])}\")\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63224493-60e1-43ee-9c03-47fe34173ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(episode_lengths, marker='o')\n",
    "\n",
    "plt.title('Episode Lengths Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Length')\n",
    "\n",
    "plt.savefig('results/pong_duration.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b40df-ad81-4aa0-8169-9ecc144bdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rolling_loss, marker='o')\n",
    "\n",
    "plt.title('Average Loss Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Loss (per 100)')\n",
    "plt.savefig('results/pong_loss.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088780ec-a245-4028-b5cf-c4a38950b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78383303-b9b7-4821-b8af-b7e749b995b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rolling_rewards_avg, marker='o')\n",
    "\n",
    "plt.title('Avg Reward Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward (per 100)')\n",
    "plt.savefig('results/pong_avg_reward.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540dc06-f9c9-470e-8e21-a536622802c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rolling_time_avg, marker='o')\n",
    "\n",
    "plt.title('Avg Lifespan Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Lifespan (per 100)')\n",
    "plt.savefig('results/pong_avg_life.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807fade6-7af7-4056-97a9-a1d785dbeb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_chart = torch.stack(val_avg).to('cpu').detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val_chart, marker='o')\n",
    "\n",
    "plt.title('Value Loss Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Loss per 100')\n",
    "plt.savefig('results/pong_rolling_val_loss.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d674a-b05c-4622-82f3-5baf369d7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rolling_val = np.convolve(val_chart, np.ones(100)/100, mode='valid')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rolling_val, marker='o')\n",
    "\n",
    "plt.title('Value Loss Over Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Loss per 100')\n",
    "plt.savefig('results/pong_rolling_val_loss.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldsrl",
   "language": "python",
   "name": "mldsrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
